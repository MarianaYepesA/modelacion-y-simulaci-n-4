# -*- coding: utf-8 -*-
"""
Created on Mon Feb  6 10:16:06 2023

@author: personal
"""

import statistics
import pandas as pd
import numpy as np
from scipy import stats
import random
import matplotlib.pyplot as plt
import math
from scipy.stats import skew
from scipy.stats import kurtosis
"""
def leer_datos():
    try:
        archivo = input("Ingresa el nombre del archivo: ")
        arch = open(archivo, 'r')
    except FileNotFoundError:
        print("File not found.")
        archivo = input("Enter a file name: ")
        arch = open(archivo, 'r')
    for line in arch:
        try:
            strip = line.strip('\n')
            data = strip.split(', ')
        except:
            data = line.strip('\n')

    try:
        data = [int(num) for num in data]
    except:
        data = [float(num) for num in data]

    return data
"""
def leer_datos(archivo):
    arch = open(archivo, 'r') 
    for line in arch:
        try:
            strip = line.strip('\n')
            data = strip.split(', ')
        except:
            data = line.strip('\n')

    try:
        data = [int(num) for num in data]
    except:
        data = [float(num) for num in data]

    return data
from pandas import *
 
# reading CSV file
data = read_csv("C:/Users/personal/Desktop/semestre5/Mode4/5_Industry_Portfolios_Daily.csv",delimiter=";")
 
# converting column data to list
temp = data['Other'].tolist()


def ancho_clase(data, num_clases):
    return int((max(data) - min(data)) / num_clases) 


def lim_inferior_clase(data, anchoclase, i):
    return min(data) + (anchoclase * i)  # el dato minimo más el ancho en cada iteración del largo de la clase

"""
def lim_superior_clase(data, anchoclase, i):
    return min(data) + (
                anchoclase * (i + 1)) - 1  # el dato mínimo más el ancho en cada iteración hasta el último de esa clase
    # min data siempre es igual pero cada iteración vamos aumentando hasta el ancho requerido
    """
def lim_superior_clase(data, anchoclase, i):
    return min(data) + (
                anchoclase * (i + 1))   # el dato mínimo más el ancho en cada iteración hasta el último de esa clase
    # min d

def marca_clase(lc_limit, uc_limit):
    return (lc_limit + uc_limit) / 2  # por definición de marca de clase

def getnums(s, e,i):
   return list(range(s, e,i))
def calc_frec_clase(data, lc_limit, uc_limit):  
    freq = 0
    for num in data:
        if num in range(int(lc_limit), int(uc_limit)+1):
            freq += 1
    return freq  # evalúa cuántas veces está cada numero en la clase


def calc_frec_clase_sinteticos(data, lc_limit, uc_limit):
    freq = 0
    for num in data:
        if lc_limit <= num <= uc_limit+1:
            freq += 1
    return freq  # evalúa cuántas veces está cada numero en la clase


def calc_frec_acum(freqs):  # ya teniendo las frecuencias le va sumando a la anterior
    freq = 0
    for class_freq in freqs:
        freq += class_freq
    return freq


def calc_frec_relativa(freqs, i, data):
    return round(freqs[i] / len(data), 3)  # cada una de las frecuencias sobre la longitud de los datos


def percentil(tabla, n ,percentil):
    p = percentil/100 * n
    for acum in range(len(tabla['Frecuencia absoluta acumulada'])):
        if p >= tabla['Frecuencia absoluta acumulada'][acum] and p< tabla['Frecuencia absoluta acumulada'][acum+1]:
            j = p-tabla['Frecuencia absoluta acumulada'][acum]
           # print(f"j={j}")
            c=acum+1
    # k: ancho de la clase
    k = (tabla['anchoclase'][c])
    #print(f"k={k}")
    #j: para pasar a la siguiente clase
    # nC: frecuencia de esa clase
    nC= tabla['Frecuencia absoluta'][c]
    ans = (tabla['liminf'][c]) + k*(j/nC)
    return ans

def estadisticosAgrupados(data, tabla):
    media= sum((tabla['Marca de clase'])*(tabla['Frecuencia absoluta']))/len(data)
    varianza= sum((tabla['Marca de clase'] - media)**2 *tabla['Frecuencia absoluta'])/len(data)
    desviacion= math.sqrt(varianza)
    percentil25= percentil(tabla, len(data), 25)
    percentil50= percentil(tabla, len(data), 50)
    percentil75= percentil(tabla, len(data), 75)
    mini= int(tabla['liminf'][0])
    maxi=int(tabla['limsup'][len(tabla)-1])
    #kurtosis = (np.sum((tabla["Frecuencia absoluta"] * (tabla["Marca de clase"])) - media)**4) / (varianza**2 * len(data))
    s=tabla['Marca de clase'].repeat(tabla['Frecuencia absoluta']).reset_index(drop=True)
    asimetria=s.skew()
    kurtosis=s.kurtosis()
    #moda = max(tabla['F Absoluta'])   
    return [len(data), media, desviacion,mini , percentil25, percentil50, percentil75, maxi,asimetria,kurtosis]

def calc_frec_relativa_absoluta(rel_freqs):
    freq = 0
    for relatFreq in rel_freqs:
        freq += relatFreq
    return round(freq, 3)  # ya teniendo las frecuencias relativas se la sumamos a la anterior

def generate_data(freq_table,k):
    gen_data = pd.Series()
    n_data_bef = freq_table.iloc[-1]["Frecuencia absoluta acumulada"]
    intervals, freq_bef = freq_table["liminf"], freq_table["Frecuencia relativa"]
    for i in range(len(intervals)):
        data_numb = int(round(freq_bef.iloc[i]*k,0))
        low_bound = (freq_table["liminf"][i])
        high_bound =( freq_table["limsup"][i])
        gen_data = pd.concat([gen_data,pd.Series(np.random.uniform(low_bound,high_bound,data_numb))])
    col_list = gen_data.values.tolist()
    #return pd.DataFrame(gen_data)
    return col_list

def datos_sinteticos1(df):
    lista=[]
    numdatos=1000
    for i in range(len(df["Frecuencia relativa"])):
     hasta=(int((df["Frecuencia relativa"][i])*numdatos))
     for j in range (hasta):
         lista.append((df2["Frecuencia relativa"][i])*df2["Marca de clase"][i])
    return lista
def datos_sinteticos_naive(df,requeridos):
    lista=[]
    for i in range(len(df["Frecuencia relativa"])):
     hasta=(int((df["Frecuencia relativa"][i])*requeridos))
     for j in range (hasta):
         lista.append((df["Marca de clase"][i]))
    w=np.vstack( lista )
    w.tolist()
    lista_naives_aplanda = [item for sublist in w for item in sublist]
    return lista_naives_aplanda

def datos_sinteticos_uniformes(df,requeridos):
    l=[]
    for i in range(len(df["Frecuencia relativa"])):
      hasta=int(requeridos*df["Frecuencia relativa"][i])
      for j in range(hasta):
       #l.append(random.uniform(df["liminf"][i], df["limsup"][i]))
       if i==0:
          l.append(random.uniform(int(df["liminf"][i]), 1+int(df["limsup"][i])))
       else:
          l.append(random.uniform(int(df["liminf"][i]), 1+int(df["limsup"][i])))
    #t=np.vstack( l )
    #t.tolist()
    #lista_uniformes_aplanda = [item for sublist in t for item in sublist]
    #return lista_uniformes_aplanda
    return l

def describe(df):
    d = df.describe()
    stats=[skew(df, axis=0, bias=True), kurtosis(df,fisher=True)]

    return d.agg(stats)


"""
def compare_all2(data,lista_uniformes_aplanada,lista_sinteticos_naive,df2):
    uniformes=pd.Series(lista_uniformes_aplanada)
    naive=pd.Series(lista_sinteticos_naive)
    listaoriginal=pd.Series(data)
    ld=listaoriginal.describe()
    ln=naive.describe()
    lu=uniformes.describe()
    ld.loc["asimetria"]=skew(data)
    ln.loc["asimetria"]=skew(lista_sinteticos_naive)
    lu.loc["asimetria"]=skew(lista_uniformes_aplanada)
    ld.loc["kurtosis"]=kurtosis(data,bias=True)
    ln.loc["kurtosis"]=kurtosis(lista_sinteticos_naive,bias=True)
    lu.loc["kurtosis"]=kurtosis(lista_uniformes_aplanada,bias=True)

    columns = {"datos crudos": ld,"datos naive":ln,"sinteticos":lu,"agrupados":estadisticosAgrupados(data, df2)}

    comparados_todos=pd.DataFrame(columns)
    
    return comparados_todos
"""
def compare_all2(data,lista_uniformes_aplanada,df2):
    uniformes=pd.Series(lista_uniformes_aplanada)
    listaoriginal=pd.Series(data)
    ld=listaoriginal.describe()
    lu=uniformes.describe()
    ld.loc["asimetria"]=skew(data)
    lu.loc["asimetria"]=skew(lista_uniformes_aplanada)
    ld.loc["kurtosis"]=kurtosis(data,bias=True)
    lu.loc["kurtosis"]=kurtosis(lista_uniformes_aplanada,bias=True)

    columns = {"datos crudos": ld,"sinteticos":lu,"agrupados":estadisticosAgrupados(data, df2)}

    comparados_todos=pd.DataFrame(columns)
    
    return comparados_todos
def compare_all(data,lista_uniformes_aplanada,lista_sinteticos_naive,df2):
    uniformes=pd.Series(lista_uniformes_aplanada)
    naive=pd.Series(lista_sinteticos_naive)
    listaoriginal=pd.Series(data)
    columns = {"datos crudos": listaoriginal.describe(),"datos naive":naive.describe(),"sinteticos":uniformes.describe(),"agrupados":estadisticosAgrupados(data, df2)}
    
    comparados_todos=pd.DataFrame(columns)
    comparados_todos["datos crudos"]+=(skew(listaoriginal, axis=0, bias=True))
    comparados_todos["datos naive"]+=(skew(naive, axis=0, bias=True))
    comparados_todos["uniformes"]+=(skew(uniformes, axis=0, bias=True))
    comparados_todos["datos crudos"]+=(kurtosis(listaoriginal,fisher=True))
    comparados_todos["datos naive"]+=(kurtosis(naive, fisher=True))
    comparados_todos["uniformes"]+=(kurtosis(uniformes, fisher=True))


    return comparados_todos
def histogramas(datos1, datos2,bins):
    fig = plt.figure(figsize=(15,5))
    
    ax1 = fig.add_subplot(1,2,1)
    ax2 = fig.add_subplot(1,2,2)

    ax1.hist(datos1,bins=bins,histtype="bar",ec="black")
    ax1.set_title("Raw data")
    ax2.hist(datos2,bins=bins,histtype="bar",ec="black")
    ax2.set_title("New data")
    plt.show()
    return fig 

def qqplot(data,uniformes):
    orig=pd.Series(data)
    u=pd.Series(uniformes)
    percentiles=np.arange(0.005,0.995,0.005)
    percentil_datos_crudos=[]
    percentil_datos_uniformes=[]
    for i in percentiles:
        percentil_datos_crudos.append(orig.quantile(q=i))
        percentil_datos_uniformes.append(u.quantile(q=i))
    plt.plot(percentil_datos_crudos,percentil_datos_uniformes)
    plt.xlabel("Datos crudos")
    plt.ylabel("Datos sintéticos ")
def generar_datos(df,requeridos):
    l=[]
    for i in range(len(["Frecuencia relativa"])):
        until=int(requeridos*df["Frecuencia relativa"][i])
        for j in range(until):
         l.append(random.uniform(df["liminf"][i], df["limsup"][i]))
    return l
def tabla_frec():
    data = leer_datos()
    print(f"Data Set:\n{data}")
    print('')
    print(f'Máximo: {max(data)}\nMínimo: {min(data)}')
    print('')
    num_clases = int(input("Cuántas clases hay? "))
    ancho = ancho_clase(data, num_clases)
    print('')
    print(f"ancho de clase: {ancho}")
    print(f"la media de los datos es: {np.mean(data)}")
    print(f"la moda es: {statistics.mode(data)}")
    print(f"la mediana es: {np.median(data)}")
    print(f"la desviación estándar es: {np.std(data)}")
    """
    print("50th percentile of arr : ",
       np.percentile(data, 50))
    print("25th percentile of arr : ",
       np.percentile(data, 25))
    print("75th percentile of arr : ",
       np.percentile(data, 75))
    """
    print()
    columns = {
        "Limites de clase (superior-inferior)": [],
        "liminf": [],
        "limsup": [],
        "anchoclase": [],
        "Marca de clase": [],
        "Frecuencia absoluta": [],
        "Frecuencia absoluta acumulada": [],
        "Frecuencia relativa": [],
        "Frecuencia relativa acumulada": [],
      #  "lista clases": [],

       # "percentil 25":[],
       # "percentil 50":[],
       # "percentil 75":[]

    }
    freqs = columns["Frecuencia absoluta"]
    rel_freqs = columns["Frecuencia relativa"]
    for i in range(num_clases):
        lim_inf = lim_inferior_clase(data, ancho, i)
        lim_sup = lim_superior_clase(data, ancho, i)
        columns["Limites de clase (superior-inferior)"] += [f"{lim_inf}-{lim_sup}"]
        columns["liminf"] += [lim_inf]
        columns["limsup"] += [lim_sup]
        columns["anchoclase"] += [ancho]
        punto_medio = marca_clase(lim_inf, lim_sup)
        columns["Marca de clase"] += [punto_medio]
        clase_frecuencia = calc_frec_clase_sinteticos(data, lim_inf, lim_sup)
        columns["Frecuencia absoluta"] += [clase_frecuencia]
        frec_acum = calc_frec_acum(freqs)
        columns["Frecuencia absoluta acumulada"] += [frec_acum]
        frec_rel = calc_frec_relativa(freqs, i, data)
        columns["Frecuencia relativa"] += [frec_rel]
        frec_rel_acum = calc_frec_relativa_absoluta(rel_freqs)
        columns["Frecuencia relativa acumulada"] += [frec_rel_acum]
       # columns["lista clases"] += [getnums(lim_inf, lim_sup, 1)]
    df = pd.DataFrame(columns)
    print(df)
    from pathlib import Path
    filepath = Path('folder/9subfolder/out.csv')
    filepath.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(filepath)
    print(f"el percentil 25 es: {percentil(df, len(data), 25)}")
    print(f"el percentil 50 es: {percentil(df, len(data), 50)}")
    print(f"el percentil 75 es: {percentil(df, len(data), 75)}")
    requeridos = int(input("Cuántos datos quieres simular? "))
    unif=datos_sinteticos_uniformes(df, requeridos)
    naive=datos_sinteticos_naive(df,requeridos)
    #unif=generate_data(df,requeridos)
    comparacion=compare_all2(data,unif,naive,df)
    print(comparacion)
    histogramas(data,unif,num_clases)
    qqplot(data,unif)
df2 = pd.read_csv("C:/Users/personal/Desktop/semestre5/Mode4/folder/9subfolder/out.csv")
def tabla_frec(archivo,num_clases):
    if type(archivo) == str:
        data = leer_datos(archivo)
    else: 
        data = archivo
    ancho = ancho_clase(data, num_clases)
    columns = {
        "Limites de clase (superior-inferior)": [],
        "liminf": [],
        "limsup": [],
        "anchoclase": [],
        "Marca de clase": [],
        "Frecuencia absoluta": [],
        "Frecuencia absoluta acumulada": [],
        "Frecuencia relativa": [],
        "Frecuencia relativa acumulada": [],
      #  "lista clases": [],

       # "percentil 25":[],
       # "percentil 50":[],
       # "percentil 75":[]

    }
    freqs = columns["Frecuencia absoluta"]
    rel_freqs = columns["Frecuencia relativa"]
    for i in range(num_clases):
        lim_inf = lim_inferior_clase(data, ancho, i)
        lim_sup = lim_superior_clase(data, ancho, i)
        columns["Limites de clase (superior-inferior)"] += [f"{lim_inf}-{lim_sup}"]
        columns["liminf"] += [lim_inf]
        columns["limsup"] += [lim_sup]
        columns["anchoclase"] += [ancho]
        punto_medio = marca_clase(lim_inf, lim_sup)
        columns["Marca de clase"] += [punto_medio]
        clase_frecuencia = calc_frec_clase_sinteticos(data, lim_inf, lim_sup)
        columns["Frecuencia absoluta"] += [clase_frecuencia]
        frec_acum = calc_frec_acum(freqs)
        columns["Frecuencia absoluta acumulada"] += [frec_acum]
        frec_rel = calc_frec_relativa(freqs, i, data)
        columns["Frecuencia relativa"] += [frec_rel]
        frec_rel_acum = calc_frec_relativa_absoluta(rel_freqs)
        columns["Frecuencia relativa acumulada"] += [frec_rel_acum]
       # columns["lista clases"] += [getnums(lim_inf, lim_sup, 1)]
    return pd.DataFrame(columns)


a = tabla_frec(temp,4)
naive=generate_data(a,10**4)
b=tabla_frec(naive, 4)
data=leer_datos(r"C:/Users/personal/Desktop/semestre5/Mode4/datos.txt")
comparacion=compare_all2(temp,naive,a)
histogramas(temp,naive,4)
plt.hist(data,bins=4)
qqplot(data,naive)
#
#estadisticosAgrupados(temp, df2)
#histograma es invariante ante permutaciones de los datos

#suma de va normales es normal pero no de distribuciones
